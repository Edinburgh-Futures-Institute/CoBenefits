import pandas as pd
import numpy as np
import duckdb


data_folder = "staticNotDeployed/"
static_folder = "static/"


# scenario_BNZ_path = "simulations_new/BNZ.csv"
# scenario_holder_path = "simulations_new/BNZ.csv"

# New data march 2025
scenario_BNZ_path = "simulations_new/march2025/BNZ_£millions_annualy.csv"
scenario_holder_path = "simulations_new/march2025/BNZ_£millions_annualy.csv"

socio_factors_path = "UK_Archetypes_global_measures.csv"

all_scenarios = [scenario_BNZ_path, scenario_holder_path]
scenario_names = ["BNZ", "test"]





df_socio = pd.read_csv(static_folder+socio_factors_path)


# Remove one row on NaN
df_socio = df_socio.dropna()


df_socio = df_socio.convert_dtypes()


df_socio


df_socio.rename(columns=lambda x: x.replace('.', '_'), inplace=True)


df_socio.columns


# EPC and gas_flag have weird values
df_socio.dtypes


set(df_socio.EPC)


set(df_socio.Gas_flag)


# Replace the string 'unknown' with pd.NA
df_socio['Gas_flag'] = df_socio['Gas_flag'].replace('Y', pd.NA)

# Step 2: Convert to numeric (converts '1.0' to 1.0 as float)
df_socio['Gas_flag'] = pd.to_numeric(df_socio['Gas_flag'], errors='coerce')

df_socio['Gas_flag'] = df_socio['Gas_flag'].astype('Int16')


# Replace the string 'unknown' with pd.NA
df_socio['EPC'] = df_socio['EPC'].replace('d', pd.NA)

# Step 2: Convert to numeric (converts '1.0' to 1.0 as float)
df_socio['EPC'] = pd.to_numeric(df_socio['EPC'], errors='coerce')

df_socio['EPC'] = df_socio['EPC'].astype('Int16')





dfs = []
for i, scenario in enumerate(all_scenarios):
    df_one_scenario = pd.read_csv(data_folder + scenario)
    df_one_scenario["scenario"] = scenario_names[i]
    dfs.append(df_one_scenario)
df = pd.concat(dfs, axis=0)
del dfs 


df


# Step: Drop rows where any column contains the value '#DIV/0!'
# There are rows with these weird values in the new dataset
df = df[~df.isin(['#DIV/0!']).any(axis=1)]


df.dtypes


# Convert columns with names from 2025 to 2050 to float
year_columns = [str(year) for year in range(2025, 2051)]
df[year_columns] = df[year_columns].astype(np.float32)


df.dtypes


# Create total column
# df["total (£m)"] = df[ [ f'{i} (£m)' for i in range(2025, 2051)]].sum(axis=1)
df["total (£m)"] = df[ [ f'{i}' for i in range(2025, 2051)]].sum(axis=1)


# Delete all the columns per hh, only keep total value columns
# Not needed with new data
# df = df.drop(columns=[ f'{i} (£/hh)' for i in range(2025, 2051)])


# Rename columns so it does not contain special characters (not needed anymore I think)
df.columns = df.columns.str.replace(' (£m)', '')


# Rename columns: replace spaces with underscores
df.columns = df.columns.str.replace(' ', '_')


df.head()


# df.astype({'total': 'float'})


df.total


np.min(df.total)


np.max(df.total)


df.dtypes





df = pd.merge(df, df_socio, left_on='Lookup_Value', right_on='LSOA_DZ_CD', how='inner')


df.head()


# Rename cobenef to always keep the same name (changed depending the version)
df.rename(columns={'Coben': 'co_benefit_type'}, inplace=True)





# Number of years merging
time_step = 5


years = list(range( 2025, 2051 ))
#years


df[["2025", "2026"]]


for i in range(0, len(years) - ( time_step - 1), time_step):
    window_years = [str(year) for year in years[i:i+5]]
    print(window_years)
    window_sum = df[window_years].sum(axis=1)
    df[f'{window_years[0]}_{window_years[-1]}'] = window_sum


df[ ['2025', '2026', '2027', '2028', '2029', '2025_2029'] ]


# Delete single values columns for space
df = df.drop(columns=[str(year) for year in years])


# CONVERT INT64 into int32
df[df.select_dtypes(np.int64).columns] = df.select_dtypes(np.int64).astype(np.int32)


df





df.dtypes





df.to_parquet('static/database.parquet')


# Not needed anymore, everything is in the same table
# df_socio.to_parquet('static/tableSocio.parquet')








DB_FILE_PATH = 'static/database.duckdb'
TABLE_NAME = "cobenefits"


con = duckdb.connect(DB_FILE_PATH)


# Create table and insert data
con.execute(f"DROP TABLE {TABLE_NAME}")

# Create table and insert data
con.execute(f"CREATE TABLE {TABLE_NAME} AS SELECT * FROM df")

# Verify data
result = con.execute(f"SELECT * FROM {TABLE_NAME} LIMIT 5").fetchall()
print("Sample data:")
print(result)

# Get and print schema
schema = con.execute(f"DESCRIBE {TABLE_NAME}").fetchall()
print("\nTable schema:")
for column in schema:
    print(f"{column[0]}: {column[1]}")

print(f"\nDatabase created and saved to: {DB_FILE_PATH}")



