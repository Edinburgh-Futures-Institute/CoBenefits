import pandas as pd
import numpy as np
import duckdb


import warnings
warnings.filterwarnings('ignore')


data_folder = "staticNotDeployed/"
static_folder = "static/"


# scenario_BNZ_path = "simulations_new/BNZ.csv"
# scenario_holder_path = "simulations_new/BNZ.csv"

# New data march 2025
# scenario_BNZ_path = data_folder + "simulations_new/march2025/BNZ_£millions_annualy.csv"
# socio_factors_path = "UK_Archetypes_global_measures.csv"

# april 2025
# scenario_BNZ_path = data_folder + "simulations_new/april2025/cleaned_total_outputs_millions.csv"
# socio_factors_path = data_folder + "simulations_new/april2025/SEF.csv"

# may 2025
scenario_BNZ_path = data_folder + "simulations_new/may2025/CB7_outputs_final_millions.csv"
socio_factors_path = data_folder + "simulations_new/april2025/SEF.csv"





# df_socio = pd.read_csv(static_folder+socio_factors_path)
df_socio = pd.read_csv(socio_factors_path)


# Remove one row on NaN
df_socio = df_socio.dropna()


df_socio = df_socio.convert_dtypes()


df_socio


df_socio.rename(columns=lambda x: x.replace('.', '_'), inplace=True)


df_socio.columns


# EPC and gas_flag have weird values
df_socio.dtypes


set(df_socio.EPC)


set(df_socio.Gas_flag)


# Replace the string 'unknown' with pd.NA
df_socio['Gas_flag'] = df_socio['Gas_flag'].replace('Y', pd.NA)

# Step 2: Convert to numeric (converts '1.0' to 1.0 as float)
df_socio['Gas_flag'] = pd.to_numeric(df_socio['Gas_flag'], errors='coerce')

df_socio['Gas_flag'] = df_socio['Gas_flag'].astype('Int16')


# Replace the string 'unknown' with pd.NA
df_socio['EPC'] = df_socio['EPC'].replace('d', pd.NA)

# Step 2: Convert to numeric (converts '1.0' to 1.0 as float)
df_socio['EPC'] = pd.to_numeric(df_socio['EPC'], errors='coerce')

df_socio['EPC'] = df_socio['EPC'].astype('Int16')


set(df_socio.Region)


# Split Eng/Wales into England and Wales in Nation column


df_socio.loc[df_socio.Region == "Wales", "Nation"] = "Wales"


df_socio.loc[(df_socio.Region != "Wales") & (df_socio.Nation == "Eng/Wales"), "Nation"] = "England"


set(df_socio.Nation)





# df_lad_NI = pd.read_csv("static/LAD/NI_DZ_LAD.csv")
df_lad_Eng = pd.read_csv("static/LAD/Eng_wales_LSOA_LADs.csv")
# df_lad_Scotland = pd.read_csv("static/LAD/Scotland_DZ_LA.csv", encoding='latin1')


df_lad_Eng.head()


# Some LADs in England were not matched correclty with the shapefiles:
# it works with the ones from the lookup files, but we need to change the values here

# Create a lookup dictionary
lookup = dict(zip(df_lad_Eng['LSOA11CD'], df_lad_Eng['LAD22CD']))
# lookup2 = dict(zip(df_lad_Eng['LSOA21CD'], df_lad_Eng['LAD22CD']))

# Loop through df and update status if there's a match
for idx, row in df_socio[df_socio.Nation == "England"].iterrows():
    lsoa = row['LSOA_DZ_CD']
    if lsoa in lookup:
        df_socio.at[idx, 'LAD'] = lookup[lsoa]





df = pd.read_csv(scenario_BNZ_path)


# Step: Drop rows where any column contains the value '#DIV/0!'
# There are rows with these weird values in the new dataset
df = df[~df.isin(['#DIV/0!']).any(axis=1)]


# To not change the queries in the app
df["scenario"] = "BNZ"


df.dtypes


# Convert columns with names from 2025 to 2050 to float
year_columns = [str(year) for year in range(2025, 2051)]
df[year_columns] = df[year_columns].astype(np.float32)


df.dtypes


# Create total column
# df["total (£m)"] = df[ [ f'{i} (£m)' for i in range(2025, 2051)]].sum(axis=1)
df["total (£m)"] = df[ [ f'{i}' for i in range(2025, 2051)]].sum(axis=1)


# Rename columns so it does not contain special characters (not needed anymore I think)
df.columns = df.columns.str.replace(' (£m)', '')


# Rename columns: replace spaces and points with underscores
df.columns = df.columns.str.replace(' ', '_')
df.columns = df.columns.str.replace('.', '_')


df.head()


df.total


np.max(df.total)


# df[df.total == np.max(df.total)]


np.mean(df.total)


df.dtypes





df = pd.merge(df, df_socio, left_on='Lookup_Value', right_on='LSOA_DZ_CD', how='left')


df.head()


# Rename cobenef to always keep the same name (changed depending the version)
df.rename(columns={'Coben': 'co_benefit_type'}, inplace=True)





# Number of years merging
time_step = 5


years = list(range( 2025, 2051 ))
#years


len(years)


df[["2025", "2026"]]


#  AGGREGATE TIME: can disable
if True:
    for i in range(0, len(years) - ( time_step - 1), time_step):
        window_years = [str(year) for year in years[i:i+5]]
        print(window_years)
        window_sum = df[window_years].sum(axis=1)
        df[f'Y{window_years[0]}_{window_years[-1]}'] = window_sum
        # df[f'{window_years[0]}_{window_years[-1]}'] = window_sum

    # Delete single values columns for space
    df = df.drop(columns=[str(year) for year in years])


# df[ ['2025', '2026', '2027', '2028', '2029', 'Y2025_2029'] ]


# CONVERT INT64 into int32
df[df.select_dtypes(np.int64).columns] = df.select_dtypes(np.int64).astype(np.int32)


df


set(df.EPC)


df.dtypes





# Sort by cb
df_sorted = df.sort_values(by='total', ascending=False)
print(df_sorted.head())


df[(df["co_benefit_type"] == "Noise") & (df["Lookup_Value"] == "N20000001")]


df





df.to_parquet('static/database.parquet')


# Not needed anymore, everything is in the same table
# df_socio.to_parquet('static/tableSocio.parquet')


df.columns


set(df.Nation)


df.co_benefit_type





df


df.columns


# Assuming df is your DataFrame and 'column_name' is the column you're interested in
# df_sampled = df.groupby('LAD').apply(lambda x: x.sample(n=10)).reset_index(drop=True)
df_sampled = df[df.Nation == "NI"]


df_sampled


df_sampled[(df_sampled["Lookup_Value"] == "N20000001") & (df_sampled["co_benefit_type"] == "Dampness")][["2028", "scenario"]]


df_sampled.to_parquet('static/database_onlyIreland.parquet')
